{{- /*
This file creates the grpc job, its corresponding service and the cleanup job.
The following values are expected from values.yaml:
  job.id              - unique identifier for the job
  job.grpcJobParameters - the command/arguments for the grpc job (as a JSON array)
  job.port            - the port for the NodePort service
  focusServer.image.tag - the image tag for the grpc container
*/ -}}
---
apiVersion: batch/v1
kind: Job
metadata:
  name: grpc-job-{{ .Values.job.id }}
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 10
  template:
    metadata:
      labels:
        app: grpc-job-{{ .Values.job.id }}
    spec:
      containers:
      - name: grpc-server
        image: localhost:5000/262399703539.dkr.ecr.eu-central-1.amazonaws.com/pzlinux:{{ .Values.focusServer.image.tag }}
        env:
          - name: PRISMA_RABBIT_MACHINE_NAME
            value: data-rabbitmq.prismaphotonics.net
          - name: PRISMA_CERTIFICATES
            value: /etc/ssl/certs
          - name: PRISMA_CONFIG
            value: /home/prisma/pz/config
        workingDir: /home/prisma
        command: {{ .Values.job.grpcJobParameters | quote }}
        ports:
          - containerPort: 5000
        volumeMounts:
          - name: certs
          - mountPath: /etc/ssl/certs
          - readOnly: true
          - name: active-python-config
          - mountPath: {{ .Values.debugEnv.persistence.mountPath | quote }}
          - name: prisma-config
          - mountPath: {{ .Values.configurations.defaultConfig.mountPath | quote }}
          - name: recordings
          - mountPath: {{ .Values.recordings.persistence.mountPath | quote }}
          - name: storage-config
          - mountPath: {{ .Values.configurations.storageConfig.mountPath | quote }}
        resources:
          limits:
            nvidia.com/gpu.shared: 1
          requests:
            nvidia.com/gpu.shared: 1
      restartPolicy: Never
      volumes:
        - name: active-python-config
          configMap:
            name: active-python-config
            defaultMode: 0755
        - name: prisma-config
          configMap:
            name: prisma-config
            defaultMode: 0755
        - name: storage-config
          configMap:
            name: storage-config
            defaultMode: 0755
        - name: recordings
          persistentVolumeClaim:
            claimName: recordings-pvc
        - name: certs
          projected:
            sources:
              - secret:
                  name: rabbitmq-tls-secret
                  items:
                    - key: ca.crt
                      path: prisma_ca.pem
                    - key: tls.crt
                      path: data-rabbitmq.prismaphotonics.net_cert.pem
                    - key: tls.key
                      path: data-rabbitmq.prismaphotonics.net_key.pem

---
apiVersion: v1
kind: Service
metadata:
  name: grpc-service-{{ .Values.job.id }}
spec:
  selector:
    app: grpc-job-{{ .Values.job.id }}
  ports:
  - name: grpc
    protocol: TCP
    port: {{ .Values.job.port }}
    targetPort: 5000
    nodePort: {{ .Values.job.port }}
  type: NodePort
---
apiVersion: batch/v1
kind: Job
metadata:
  name: cleanup-job-{{ .Values.job.id }}
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 10
  template:
    metadata:
      labels:
        app: cleanup-job-{{ .Values.job.id }}
    spec:
      serviceAccountName: {{ .Values.cleanupService.serviceAccountName }}
      containers:
      - name: cleanup-container
        image: localhost:5000/262399703539.dkr.ecr.eu-central-1.amazonaws.com/cleanup-grpc:1.1
        env:
          - name: CPU_USAGE_THRESHOLD
            value: "1"
          - name: ENABLE_CPU_USAGE_CHECK
            value: "true"
          - name: MAX_CPU_USAGE_COUNT
            value: "5"
        command: ["/bin/sh", "-c"]
        args:
          - |
            CPU_USAGE_THRESHOLD=${CPU_USAGE_THRESHOLD:-1}
            ENABLE_CPU_USAGE_CHECK=${ENABLE_CPU_USAGE_CHECK:-true}
            MAX_CPU_USAGE_COUNT=${MAX_CPU_USAGE_COUNT:-5}

            cpu_usage_count=0

            while true; do
                if ! kubectl get job grpc-job-{{ .Values.job.id }} > /dev/null 2>&1; then
                    break
                fi

                job_status=$(kubectl get job grpc-job-{{ .Values.job.id }} -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}')
                job_failed=$(kubectl get job grpc-job-{{ .Values.job.id }} -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}')

                if [ "$job_status" = "True" ] || [ "$job_failed" = "True" ]; then
                    break
                fi

                if [ "$ENABLE_CPU_USAGE_CHECK" = true ]; then
                    pod_name=$(kubectl get pods --selector=job-name=grpc-job-{{ .Values.job.id }} -o jsonpath='{.items[0].metadata.name}')
                    cpu_usage=$(kubectl top pod $pod_name --no-headers 2>/dev/null | awk '{print $2}' | sed 's/m//')

                    if [ "$cpu_usage" -le "$CPU_USAGE_THRESHOLD" ] 2>/dev/null; then
                        cpu_usage_count=$((cpu_usage_count + 1))
                        if [ "$cpu_usage_count" -ge "$MAX_CPU_USAGE_COUNT" ]; then
                            echo "CPU usage has been $CPU_USAGE_THRESHOLD or less for $MAX_CPU_USAGE_COUNT loops, exiting."
                            break
                        fi
                    else
                        cpu_usage_count=0
                    fi
                fi

                sleep 10
            done

            kubectl delete service grpc-service-{{ .Values.job.id }} --ignore-not-found
            kubectl delete job grpc-job-{{ .Values.job.id }} --ignore-not-found --grace-period=0 --force
            kubectl delete job cleanup-job-{{ .Values.job.id }} --ignore-not-found --grace-period=0 --force

            queue_name=$(curl -u prisma:prismapanda http://rabbitmq-panda:15672/api/queues | grep -o "\"name\":\"grpc-job-{{ .Values.job.id }}-[^\"]*\"" | sed 's/"name":"//;s/"//')
            curl -u prisma:prismapanda -X DELETE http://rabbitmq-panda:15672/api/queues/%2F/$queue_name
      restartPolicy: Never
